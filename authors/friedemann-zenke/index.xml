<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Friedemann Zenke | NMI</title>
    <link>https://eneftci.github.io/authors/friedemann-zenke/</link>
      <atom:link href="https://eneftci.github.io/authors/friedemann-zenke/index.xml" rel="self" type="application/rss+xml" />
    <description>Friedemann Zenke</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 06 Dec 2020 17:21:59 -0700</lastBuildDate>
    <image>
      <url>https://eneftci.github.io/images/logo_hu7945e16b4c080225a93098c1772fbb4a_6934_300x300_fit_box_2.png</url>
      <title>Friedemann Zenke</title>
      <link>https://eneftci.github.io/authors/friedemann-zenke/</link>
    </image>
    
    <item>
      <title>New Article Proceedings of the IEEE on Brain-Inspired Learning on Neuromorphic Substrates</title>
      <link>https://eneftci.github.io/post/zenke_neftci20/</link>
      <pubDate>Sun, 06 Dec 2020 17:21:59 -0700</pubDate>
      <guid>https://eneftci.github.io/post/zenke_neftci20/</guid>
      <description>&lt;p&gt;Neuromorphic hardware strives to emulate brain-like neural networks and thus holds the promise for scalable, low-power information processing on temporal data streams. Yet, to solve real-world problems, these networks need to be trained. However, training on neuromorphic substrates creates significant challenges due to the offline character and the required nonlocal computations of gradient-based learning algorithms. This article provides a mathematical framework for the design of practical online learning algorithms for neuromorphic substrates. Specifically, we show a direct connection between RTRL, an online algorithm for computing gradients in conventional RNNs, and biologically plausible learning rules for training SNNs. Furthermore, we motivate a sparse approximation based on block-diagonal Jacobians, which reduces the algorithm&amp;rsquo;s computational complexity, diminishes the nonlocal information requirements, and empirically leads to good learning performance, thereby improving its applicability to neuromorphic substrates. In summary, our framework bridges the gap between synaptic plasticity and gradient-based approaches from deep learning and lays the foundations for powerful information processing on future neuromorphic hardware systems.&lt;/p&gt;
&lt;p&gt;See &lt;a href=../../publication/zenke-neftci-21/ &gt;publication here &lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Brain-Inspired Learning on Neuromorphic Substrates</title>
      <link>https://eneftci.github.io/publication/zenke-neftci-20/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://eneftci.github.io/publication/zenke-neftci-20/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
